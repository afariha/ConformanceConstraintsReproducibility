%!TEX root = paper.tex
%\section{Summary and Future Directions}
\looseness-1
We introduced \dis, and the notion of \nc tuples for trusted
machine learning. We presented an efficient and scalable approach for
synthesizing \dis and empirically demonstrated their effectiveness in tagging
\nc tuples and quantify data drift.
% The experiments validate our theory and our principle of using low-variance
% \views to generate effective \dis.
We studied two use-cases from a large pool of potential applications using
linear \dis. In future, we want to explore more powerful nonlinear \dis using
autoencoders. Moreover, we plan to explore approaches to learn \dis in a
decision-tree-like structure where categorical attributes will guide the
splitting conditions and leaves will contain simple \dis.



